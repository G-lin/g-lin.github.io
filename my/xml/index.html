<!DOCTYPE html>
<html>

<head>
	<meta charset="utf-8">
	<title>lalala</title>
</head>

<body>
	<!-- <h2>Face Detection Camera Example</h2>
		<p>
			Click <b>Start/Stop</b> button to start or stop the camera capture.<br> The <b>videoInput</b> is a &lt;video&gt; element used as face detector input. The <b>canvasOutput</b> is a &lt;canvas&gt; element used as face detector output.<br> The code of &lt;textarea&gt; will be executed when video is started. You can modify the code to investigate more.
		</p> -->
	<div>
		<div class="control"><button id="startAndStop" disabled>Start</button></div>
		<textarea style="display:none;" class="code" rows="1" cols="100" id="codeEditor" spellcheck="false">
</textarea>
	</div>
	<p class="err" id="errorMessage"></p>
	<div>
		<table cellpadding="0" cellspacing="0" width="0" border="0">
			<tr>
				<td style="display:none;">
					<video id="videoInput" width=320 height=240></video>
				</td>
				<td>
					<canvas id="canvasOutput" width=320 height=240></canvas>
				</td>
				<td></td>
				<td></td>
			</tr>
			<tr style="display:none;">
				<td>
					<div class="caption">videoInput</div>
				</td>
				<td>
					<div class="caption">canvasOutput</div>
				</td>
				<td></td>
				<td></td>
			</tr>
		</table>
		<div></div>
	</div>
	<!--<script src="https://webrtc.github.io/adapter/adapter-5.0.4.js" type="text/javascript"></script>-->
	<script src="../js/utils.js" type="text/javascript"></script>
	<script id="codeSnippet" type="text/code-snippet">
			let video = document.getElementById('videoInput');
					let src = new cv.Mat(video.height, video.width, cv.CV_8UC4);
					let dst = new cv.Mat(video.height, video.width, cv.CV_8UC4);
					let gray = new cv.Mat();
					let cap = new cv.VideoCapture(video);
					let msize = new cv.Size(0, 0);

					let faces = new cv.RectVector();
					let eyes = new cv.RectVector();

					let faceCascade = new cv.CascadeClassifier();
					let eyeCascade = new cv.CascadeClassifier();


					// load pre-trained classifiers
					faceCascade.load('haarcascade_frontalface_default.xml');
					eyeCascade.load('haarcascade_eye.xml');
                    
                    //公共变量

					const FPS = 20;

                    let face;
			        let roiGray;
			        let roiSrc;

			        let eye;
					let point1;
					let point2;

					let begin;
					let delay;

					function processVideo() {
					    try {
					        if (!streaming) {
					            // clean and stop.
					            src.delete();
					            dst.delete();
								gray.delete();
								
					            faces.delete();
								faceCascade.delete();

								eyeCascade.delete();
								eyes.delete();
								
					            return;
					        }

					        begin = Date.now();
					        // start processing.
					        cap.read(src);
					        src.copyTo(dst);//****关键
					        cv.cvtColor(dst, gray, cv.COLOR_RGBA2GRAY, 0);
					        // detect faces.
					        faceCascade.detectMultiScale(gray, faces, 1.1, 3, 0,msize,msize);
					        // draw faces.		        

					        for (let i = 0; i < faces.size(); ++i) {

								face = faces.get(i);
								roiGray = gray.roi(faces.get(i));
								roiSrc = dst.roi(faces.get(i));

								for (let j = 0; j < eyes.size(); ++j) {
									//console.log(eyes.size());
									eye = eyes.get(j);
									point1 = new cv.Point(eye.x, eye.y);
									point2 = new cv.Point(eye.x + eye.width, eye.y + eye.height);
									cv.rectangle(roiSrc, point1, point2, [0, 0, 255, 255]);
								}
								roiGray.delete(); roiSrc.delete();

							}
							
					        cv.imshow('canvasOutput', dst);

							// schedule the next one.
					        delay = 1000/FPS - (Date.now() - begin);
					        setTimeout(processVideo, delay);

					    } catch (err) {
					        utils.printError(err);
					    }
					};
					
					// schedule the first one.
					setTimeout(processVideo, 0);
				</script>
	<script type="text/javascript">
		let utils = new Utils('errorMessage');

		utils.loadCode('codeSnippet', 'codeEditor');

		let streaming = false;
		let videoInput = document.getElementById('videoInput');
		let startAndStop = document.getElementById('startAndStop');
		let canvasOutput = document.getElementById('canvasOutput');
		let canvasContext = canvasOutput.getContext('2d');

		let reStart = () => {
			if (!streaming) {
				utils.clearError();
				utils.startCamera('qvga', onVideoStarted, 'videoInput');
			} else {
				utils.stopCamera();
				onVideoStopped();
			}
		}

		startAndStop.onclick = reStart;

		function onVideoStarted() {
			streaming = true;
			startAndStop.innerText = 'Stop';
			videoInput.width = videoInput.videoWidth;
			videoInput.height = videoInput.videoHeight;
			utils.executeCode('codeEditor');
		}

		function onVideoStopped() {
			streaming = false;
			canvasContext.clearRect(0, 0, canvasOutput.width, canvasOutput.height);
			startAndStop.innerText = 'Start';
		}

		utils.loadOpenCv(() => {
			let faceCascadeFile = 'haarcascade_frontalface_default.xml';
			utils.createFileFromUrl(faceCascadeFile, faceCascadeFile, () => {
				let eyeCascadeFile = 'haarcascade_eye.xml';
				utils.createFileFromUrl(eyeCascadeFile, eyeCascadeFile, () => {
					startAndStop.removeAttribute('disabled');
					reStart();
				});
			});
		});
	</script>
</body>

</html>